{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences with Universal tagset\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')], [('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')], [('Lorillard', 'NOUN'), ('Inc.', 'NOUN'), (',', '.'), ('the', 'DET'), ('unit', 'NOUN'), ('of', 'ADP'), ('New', 'ADJ'), ('York-based', 'ADJ'), ('Loews', 'NOUN'), ('Corp.', 'NOUN'), ('that', 'DET'), ('*T*-2', 'X'), ('makes', 'VERB'), ('Kent', 'NOUN'), ('cigarettes', 'NOUN'), (',', '.'), ('stopped', 'VERB'), ('using', 'VERB'), ('crocidolite', 'NOUN'), ('in', 'ADP'), ('its', 'PRON'), ('Micronite', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('in', 'ADP'), ('1956', 'NUM'), ('.', '.')], [('Although', 'ADP'), ('preliminary', 'ADJ'), ('findings', 'NOUN'), ('were', 'VERB'), ('reported', 'VERB'), ('*-2', 'X'), ('more', 'ADV'), ('than', 'ADP'), ('a', 'DET'), ('year', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('the', 'DET'), ('latest', 'ADJ'), ('results', 'NOUN'), ('appear', 'VERB'), ('in', 'ADP'), ('today', 'NOUN'), (\"'s\", 'PRT'), ('New', 'NOUN'), ('England', 'NOUN'), ('Journal', 'NOUN'), ('of', 'ADP'), ('Medicine', 'NOUN'), (',', '.'), ('a', 'DET'), ('forum', 'NOUN'), ('likely', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('bring', 'VERB'), ('new', 'ADJ'), ('attention', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('problem', 'NOUN'), ('.', '.')], [('A', 'DET'), ('Lorillard', 'NOUN'), ('spokewoman', 'NOUN'), ('said', 'VERB'), (',', '.'), ('``', '.'), ('This', 'DET'), ('is', 'VERB'), ('an', 'DET'), ('old', 'ADJ'), ('story', 'NOUN'), ('.', '.')], [('We', 'PRON'), (\"'re\", 'VERB'), ('talking', 'VERB'), ('about', 'ADP'), ('years', 'NOUN'), ('ago', 'ADP'), ('before', 'ADP'), ('anyone', 'NOUN'), ('heard', 'VERB'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('having', 'VERB'), ('any', 'DET'), ('questionable', 'ADJ'), ('properties', 'NOUN'), ('.', '.')], [('There', 'DET'), ('is', 'VERB'), ('no', 'DET'), ('asbestos', 'NOUN'), ('in', 'ADP'), ('our', 'PRON'), ('products', 'NOUN'), ('now', 'ADV'), ('.', '.'), (\"''\", '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Check first few tagged sentences\n",
    "print(nltk_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in problem, let's divide the Treebank dataset into train and validation sets in ratio of 95:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test dataset\n",
    "train_set, test_set = train_test_split(nltk_data, random_state = 1000, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n",
      "[[('She', 'PRON'), ('says', 'VERB'), ('0', 'X'), ('she', 'PRON'), ('offered', 'VERB'), ('Mrs.', 'NOUN'), ('Yeargin', 'NOUN'), ('a', 'DET'), ('quiet', 'ADJ'), ('resignation', 'NOUN'), ('and', 'CONJ'), ('thought', 'VERB'), ('0', 'X'), ('she', 'PRON'), ('could', 'VERB'), ('help', 'VERB'), ('*-1', 'X'), ('save', 'VERB'), ('her', 'PRON'), ('teaching', 'NOUN'), ('certificate', 'NOUN'), ('.', '.')], [('Program', 'NOUN'), ('trading', 'NOUN'), ('money', 'NOUN'), ('managers', 'NOUN'), ('have', 'VERB'), ('gained', 'VERB'), ('control', 'NOUN'), ('over', 'ADP'), ('a', 'DET'), ('big', 'ADJ'), ('chunk', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('invested', 'VERB'), ('funds', 'NOUN'), ('in', 'ADP'), ('this', 'DET'), ('country', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('the', 'DET'), ('pressures', 'NOUN'), ('*ICH*-2', 'X'), ('on', 'ADP'), ('such', 'ADJ'), ('money', 'NOUN'), ('managers', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('produce', 'VERB'), ('consistent', 'ADJ'), ('profits', 'NOUN'), ('has', 'VERB'), ('wedded', 'VERB'), ('them', 'PRON'), ('to', 'PRT'), ('the', 'DET'), ('ability', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('move', 'VERB'), ('rapidly', 'ADV'), ('in', 'ADP'), ('and', 'CONJ'), ('out', 'ADP'), ('the', 'DET'), ('market', 'NOUN'), ('that', 'ADP'), ('program', 'NOUN'), ('trading', 'NOUN'), ('gives', 'VERB'), ('them', 'PRON'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('two', 'NUM'), ('professors', 'NOUN'), ('represent', 'VERB'), ('different', 'ADJ'), ('ends', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('political', 'ADJ'), ('spectrum', 'NOUN'), ('--', '.'), ('Mr.', 'NOUN'), ('Kurland', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('conservative', 'ADJ'), ('and', 'CONJ'), ('Mr.', 'NOUN'), ('Tribe', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('liberal', 'NOUN'), ('.', '.')], [('Some', 'DET'), ('of', 'ADP'), ('the', 'DET'), ('surge', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('stock', 'NOUN'), (\"'s\", 'PRT'), ('price', 'NOUN'), ('appeared', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('linked', 'VERB'), ('*-39', 'X'), ('to', 'PRT'), ('revived', 'VERB'), ('takeover', 'NOUN'), ('speculation', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-28', 'X'), ('has', 'VERB'), ('contributed', 'VERB'), ('to', 'PRT'), ('volatility', 'NOUN'), ('of', 'ADP'), ('Campbell', 'NOUN'), ('shares', 'NOUN'), ('in', 'ADP'), ('recent', 'ADJ'), ('months', 'NOUN'), ('.', '.')], [('A', 'DET'), ('spokesman', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('IRS', 'NOUN'), ('confirmed', 'VERB'), ('that', 'ADP'), ('``', '.'), ('there', 'DET'), ('has', 'VERB'), ('been', 'VERB'), ('correspondence', 'NOUN'), ('mailed', 'VERB'), ('*', 'X'), ('about', 'ADP'), ('incomplete', 'ADJ'), ('8300s', 'NOUN'), (',', '.'), (\"''\", '.'), ('but', 'CONJ'), ('he', 'PRON'), ('declined', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('say', 'VERB'), ('why', 'ADV'), ('the', 'DET'), ('letters', 'NOUN'), ('were', 'VERB'), ('sent', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('lawyers', 'NOUN'), ('now', 'ADV'), ('.', '.')], [('The', 'DET'), ('new', 'ADJ'), ('plant', 'NOUN'), (',', '.'), ('located', 'VERB'), ('*', 'X'), ('in', 'ADP'), ('Chinchon', 'NOUN'), ('about', 'ADP'), ('60', 'NUM'), ('miles', 'NOUN'), ('from', 'ADP'), ('Seoul', 'NOUN'), (',', '.'), ('will', 'VERB'), ('help', 'VERB'), ('*-2', 'X'), ('meet', 'VERB'), ('increasing', 'VERB'), ('and', 'CONJ'), ('diversifying', 'VERB'), ('demand', 'NOUN'), ('for', 'ADP'), ('control', 'NOUN'), ('products', 'NOUN'), ('in', 'ADP'), ('South', 'NOUN'), ('Korea', 'NOUN'), (',', '.'), ('the', 'DET'), ('company', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('rifles', 'NOUN'), ('were', 'VERB'), (\"n't\", 'ADV'), ('loaded', 'VERB'), ('*-1', 'X'), ('.', '.')], [('In', 'ADP'), ('national', 'ADJ'), ('over-the-counter', 'ADJ'), ('trading', 'NOUN'), ('yesterday', 'NOUN'), (',', '.'), ('POP', 'NOUN'), ('plunged', 'VERB'), ('$', '.'), ('4', 'NUM'), ('*U*', 'X'), ('to', 'PRT'), ('$', '.'), ('14.75', 'NUM'), ('*U*', 'X'), ('.', '.')], [('*-2', 'X'), ('Given', 'VERB'), ('*-3', 'X'), ('that', 'DET'), ('choice', 'NOUN'), (',', '.'), ('associates', 'NOUN'), ('of', 'ADP'), ('Mr.', 'NOUN'), ('Hahn', 'NOUN'), ('and', 'CONJ'), ('industry', 'NOUN'), ('observers', 'NOUN'), ('say', 'VERB'), ('0', 'X'), ('the', 'DET'), ('former', 'ADJ'), ('university', 'NOUN'), ('president', 'NOUN'), ('--', '.'), ('who', 'PRON'), ('*T*-1', 'X'), ('has', 'VERB'), ('developed', 'VERB'), ('a', 'DET'), ('reputation', 'NOUN'), ('for', 'ADP'), ('*', 'X'), ('not', 'ADV'), ('overpaying', 'VERB'), ('for', 'ADP'), ('anything', 'NOUN'), ('--', '.'), ('would', 'VERB'), ('fold', 'VERB'), ('.', '.')], [('Intermec', 'NOUN'), ('Corp.', 'NOUN'), (',', '.'), ('offering', 'VERB'), ('of', 'ADP'), ('1,050,000', 'NUM'), ('common', 'ADJ'), ('shares', 'NOUN'), (',', '.'), ('via', 'ADP'), ('Goldman', 'NOUN'), (',', '.'), ('Sachs', 'NOUN'), ('&', 'CONJ'), ('Co.', 'NOUN'), ('and', 'CONJ'), ('Piper', 'NOUN'), (',', '.'), ('Jaffray', 'NOUN'), ('&', 'CONJ'), ('Hopwood', 'NOUN'), ('Inc', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "#Check length of training and test set\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "\n",
    "#Check first few tagged sentences of training set \n",
    "print(train_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95414"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of tagged words from training set\n",
    "train_tagged_words = [tup for sentence in train_set for tup in sentence]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PRON'),\n",
       " ('says', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('she', 'PRON'),\n",
       " ('offered', 'VERB'),\n",
       " ('Mrs.', 'NOUN'),\n",
       " ('Yeargin', 'NOUN'),\n",
       " ('a', 'DET'),\n",
       " ('quiet', 'ADJ'),\n",
       " ('resignation', 'NOUN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check first few words along with their tags\n",
    "train_tagged_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She',\n",
       " 'says',\n",
       " '0',\n",
       " 'she',\n",
       " 'offered',\n",
       " 'Mrs.',\n",
       " 'Yeargin',\n",
       " 'a',\n",
       " 'quiet',\n",
       " 'resignation']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of words/tokens from training set\n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12032\n"
     ]
    }
   ],
   "source": [
    "# Get vocabulary from training set\n",
    "vocabulary = set(tokens)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.', 'PRON', 'X', 'NOUN', 'ADP', 'VERB', 'ADJ', 'ADV', 'DET', 'CONJ', 'PRT', 'NUM'}\n"
     ]
    }
   ],
   "source": [
    "# Get list of tags\n",
    "tags = set([pair[1] for pair in train_tagged_words])\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 12 tags in the tagset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the HMM algorithm to tag the words. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word. In other words, to every word w, assign the tag t that maximises the likelihood P(t/w).\n",
    "\n",
    "Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t).\n",
    "\n",
    "Now:\n",
    "\n",
    "- Emission probability OR P(w/t) is the probability of a given word for a given tag. This can be computed based on the fraction of given word for given tag to the total count of that tag, ie: P(w/t) = count(w, t) / count(t).\n",
    "\n",
    "- Transition probability OR P(t) is the probability of tag, and in a tagging task, we assume that a tag will depend only on the previous tag (Markov order 1 assumption). In other words, the probability of say a tag being NN will depend only on the previous tag t(n-1). So for e.g. if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(tags)\n",
    "v = len(vocabulary)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Emission probability i.e. word given tag\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this function for few words and tags and check the emission probability of these pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " bright\n",
      "(0, 2592)\n",
      "(6, 27347)\n",
      "\n",
      " is\n",
      "(0, 8257)\n",
      "(630, 12848)\n",
      "\n",
      " growing\n",
      "(22, 12848)\n",
      "(0, 9365)\n"
     ]
    }
   ],
   "source": [
    "# bright\n",
    "print(\"\\n\", \"bright\")\n",
    "print(word_given_tag('language', 'PRON'))\n",
    "print(word_given_tag('language', 'NOUN'))\n",
    "\n",
    "# is\n",
    "print(\"\\n\", \"is\")\n",
    "print(word_given_tag('is', 'DET'))\n",
    "print(word_given_tag('is', 'VERB'))\n",
    "\n",
    "# growing\n",
    "print(\"\\n\", \"growing\")\n",
    "print(word_given_tag('growing', 'VERB'))\n",
    "print(word_given_tag('growing', 'ADP'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute transition probability i.e. probability of a tag occuring after another tag: tag2(t2) given tag1 (t1)\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this function on few tags and check the transition probabilities for few tags pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6080)\n",
      "(4252, 6080)\n",
      "(5264, 8257)\n",
      "(450, 12848)\n",
      "(1262, 2592)\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "print(t2_given_t1('PRON', 'ADJ'))\n",
    "print(t2_given_t1('NOUN', 'ADJ'))\n",
    "print(t2_given_t1('NOUN', 'DET'))\n",
    "print(t2_given_t1('PRON', 'VERB'))\n",
    "print(t2_given_t1('VERB', 'PRON'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store these emission probabilities in a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags where each column is t2, each row is t1\n",
    "# M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.18597281e-02, 6.58974126e-02, 2.66834944e-02, 2.22212210e-01,\n",
       "        9.11385566e-02, 8.96060616e-02, 4.42621484e-02, 5.30965477e-02,\n",
       "        1.74073741e-01, 5.79644814e-02, 2.34382041e-03, 8.07716548e-02],\n",
       "       [3.93518507e-02, 8.10185168e-03, 9.06635821e-02, 2.12191358e-01,\n",
       "        2.27623452e-02, 4.86882716e-01, 7.33024701e-02, 3.47222239e-02,\n",
       "        8.87345709e-03, 4.62962966e-03, 1.11882715e-02, 7.33024674e-03],\n",
       "       [1.64033830e-01, 5.56885265e-02, 7.48364478e-02, 6.23902977e-02,\n",
       "        1.44566774e-01, 2.04882726e-01, 1.64352953e-02, 2.45731603e-02,\n",
       "        5.45715652e-02, 1.03717884e-02, 1.84936970e-01, 2.71262159e-03],\n",
       "       [2.40209162e-01, 4.38804971e-03, 2.92170979e-02, 2.63648659e-01,\n",
       "        1.77350342e-01, 1.46341458e-01, 1.23962406e-02, 1.72962304e-02,\n",
       "        1.29081802e-02, 4.24909480e-02, 4.42461707e-02, 9.50744096e-03],\n",
       "       [3.96155901e-02, 6.94073662e-02, 3.55579294e-02, 3.20128143e-01,\n",
       "        1.67645495e-02, 8.32888391e-03, 1.07848369e-01, 1.31340092e-02,\n",
       "        3.24399352e-01, 9.61025071e-04, 1.38814736e-03, 6.24666326e-02],\n",
       "       [3.47135738e-02, 3.50249074e-02, 2.17387915e-01, 1.11145705e-01,\n",
       "        9.23100859e-02, 1.68742210e-01, 6.46793246e-02, 8.11021179e-02,\n",
       "        1.34729147e-01, 5.52615197e-03, 3.13667506e-02, 2.32721046e-02],\n",
       "       [6.54605255e-02, 6.57894765e-04, 2.08881572e-02, 6.99342132e-01,\n",
       "        7.73026347e-02, 1.15131577e-02, 6.71052635e-02, 4.60526301e-03,\n",
       "        4.60526301e-03, 1.71052627e-02, 1.06907897e-02, 2.07236838e-02],\n",
       "       [1.36015967e-01, 1.52976392e-02, 2.22813431e-02, 3.29231806e-02,\n",
       "        1.18390426e-01, 3.46192211e-01, 1.29364818e-01, 8.18091109e-02,\n",
       "        6.65114745e-02, 6.98370486e-03, 1.39674097e-02, 3.02627198e-02],\n",
       "       [1.79241858e-02, 3.75439017e-03, 4.56582308e-02, 6.37519658e-01,\n",
       "        9.32542048e-03, 3.99660878e-02, 2.05038145e-01, 1.27164833e-02,\n",
       "        5.32881171e-03, 4.84437449e-04, 2.42218724e-04, 2.20419038e-02],\n",
       "       [3.72786596e-02, 5.91798685e-02, 8.38769786e-03, 3.46691519e-01,\n",
       "        5.31220883e-02, 1.59366265e-01, 1.17427774e-01, 5.49860187e-02,\n",
       "        1.16961792e-01, 4.65983234e-04, 5.12581551e-03, 4.10065241e-02],\n",
       "       [4.32220027e-02, 1.86640471e-02, 1.34250168e-02, 2.49508843e-01,\n",
       "        2.03012452e-02, 3.99148643e-01, 8.48068073e-02, 9.49574355e-03,\n",
       "        9.98690277e-02, 2.29207589e-03, 1.96463661e-03, 5.73018976e-02],\n",
       "       [1.16438359e-01, 1.48898154e-03, 2.12030977e-01, 3.52590829e-01,\n",
       "        3.48421670e-02, 1.72721855e-02, 3.42465751e-02, 2.97796307e-03,\n",
       "        3.27575929e-03, 1.39964260e-02, 2.62060743e-02, 1.84633717e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>PRON</th>\n",
       "      <th>X</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>DET</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.091860</td>\n",
       "      <td>0.065897</td>\n",
       "      <td>0.026683</td>\n",
       "      <td>0.222212</td>\n",
       "      <td>0.091139</td>\n",
       "      <td>0.089606</td>\n",
       "      <td>0.044262</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.174074</td>\n",
       "      <td>0.057964</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.080772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.039352</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.090664</td>\n",
       "      <td>0.212191</td>\n",
       "      <td>0.022762</td>\n",
       "      <td>0.486883</td>\n",
       "      <td>0.073302</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.164034</td>\n",
       "      <td>0.055689</td>\n",
       "      <td>0.074836</td>\n",
       "      <td>0.062390</td>\n",
       "      <td>0.144567</td>\n",
       "      <td>0.204883</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.054572</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.184937</td>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.240209</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.029217</td>\n",
       "      <td>0.263649</td>\n",
       "      <td>0.177350</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.042491</td>\n",
       "      <td>0.044246</td>\n",
       "      <td>0.009507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.039616</td>\n",
       "      <td>0.069407</td>\n",
       "      <td>0.035558</td>\n",
       "      <td>0.320128</td>\n",
       "      <td>0.016765</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>0.107848</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>0.324399</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.062467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.035025</td>\n",
       "      <td>0.217388</td>\n",
       "      <td>0.111146</td>\n",
       "      <td>0.092310</td>\n",
       "      <td>0.168742</td>\n",
       "      <td>0.064679</td>\n",
       "      <td>0.081102</td>\n",
       "      <td>0.134729</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.031367</td>\n",
       "      <td>0.023272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>0.699342</td>\n",
       "      <td>0.077303</td>\n",
       "      <td>0.011513</td>\n",
       "      <td>0.067105</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.017105</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>0.020724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.136016</td>\n",
       "      <td>0.015298</td>\n",
       "      <td>0.022281</td>\n",
       "      <td>0.032923</td>\n",
       "      <td>0.118390</td>\n",
       "      <td>0.346192</td>\n",
       "      <td>0.129365</td>\n",
       "      <td>0.081809</td>\n",
       "      <td>0.066511</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.030263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.045658</td>\n",
       "      <td>0.637520</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.205038</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.022042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.037279</td>\n",
       "      <td>0.059180</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.346692</td>\n",
       "      <td>0.053122</td>\n",
       "      <td>0.159366</td>\n",
       "      <td>0.117428</td>\n",
       "      <td>0.054986</td>\n",
       "      <td>0.116962</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.041007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.043222</td>\n",
       "      <td>0.018664</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>0.249509</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.399149</td>\n",
       "      <td>0.084807</td>\n",
       "      <td>0.009496</td>\n",
       "      <td>0.099869</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.057302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.212031</td>\n",
       "      <td>0.352591</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>0.026206</td>\n",
       "      <td>0.184634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .      PRON         X      NOUN       ADP      VERB       ADJ  \\\n",
       ".     0.091860  0.065897  0.026683  0.222212  0.091139  0.089606  0.044262   \n",
       "PRON  0.039352  0.008102  0.090664  0.212191  0.022762  0.486883  0.073302   \n",
       "X     0.164034  0.055689  0.074836  0.062390  0.144567  0.204883  0.016435   \n",
       "NOUN  0.240209  0.004388  0.029217  0.263649  0.177350  0.146341  0.012396   \n",
       "ADP   0.039616  0.069407  0.035558  0.320128  0.016765  0.008329  0.107848   \n",
       "VERB  0.034714  0.035025  0.217388  0.111146  0.092310  0.168742  0.064679   \n",
       "ADJ   0.065461  0.000658  0.020888  0.699342  0.077303  0.011513  0.067105   \n",
       "ADV   0.136016  0.015298  0.022281  0.032923  0.118390  0.346192  0.129365   \n",
       "DET   0.017924  0.003754  0.045658  0.637520  0.009325  0.039966  0.205038   \n",
       "CONJ  0.037279  0.059180  0.008388  0.346692  0.053122  0.159366  0.117428   \n",
       "PRT   0.043222  0.018664  0.013425  0.249509  0.020301  0.399149  0.084807   \n",
       "NUM   0.116438  0.001489  0.212031  0.352591  0.034842  0.017272  0.034247   \n",
       "\n",
       "           ADV       DET      CONJ       PRT       NUM  \n",
       ".     0.053097  0.174074  0.057964  0.002344  0.080772  \n",
       "PRON  0.034722  0.008873  0.004630  0.011188  0.007330  \n",
       "X     0.024573  0.054572  0.010372  0.184937  0.002713  \n",
       "NOUN  0.017296  0.012908  0.042491  0.044246  0.009507  \n",
       "ADP   0.013134  0.324399  0.000961  0.001388  0.062467  \n",
       "VERB  0.081102  0.134729  0.005526  0.031367  0.023272  \n",
       "ADJ   0.004605  0.004605  0.017105  0.010691  0.020724  \n",
       "ADV   0.081809  0.066511  0.006984  0.013967  0.030263  \n",
       "DET   0.012716  0.005329  0.000484  0.000242  0.022042  \n",
       "CONJ  0.054986  0.116962  0.000466  0.005126  0.041007  \n",
       "PRT   0.009496  0.099869  0.002292  0.001965  0.057302  \n",
       "NUM   0.002978  0.003276  0.013996  0.026206  0.184634  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a dataframe for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".       0.091860\n",
       "PRON    0.065897\n",
       "X       0.026683\n",
       "NOUN    0.222212\n",
       "ADP     0.091139\n",
       "VERB    0.089606\n",
       "ADJ     0.044262\n",
       "ADV     0.053097\n",
       "DET     0.174074\n",
       "CONJ    0.057964\n",
       "PRT     0.002344\n",
       "NUM     0.080772\n",
       "Name: ., dtype: float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the probability of sentence starting with a particular tag\n",
    "tags_df.loc['.', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from above result that probability of a sentenc starting with Noun is highest (22%) followed by Determiner (17.4%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# heatmap of tags matrix\n",
    "# T(i, j) means P(tag j given tag i)\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter out the pair of tags with high probabilities of occuring in conjuction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequent tags\n",
    "tags_frequent = tags_df[tags_df>0.5]\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_frequent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed from above heatmap that probability of noun being followed by Adjective and Determiner are highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Algorithm\n",
    "\n",
    "Let's now use the computed probabilities P(w, tag) and P(t2, t1) to assign tags to each word in the document. We'll run through each word w and compute P(tag/w)=P(w/tag).P(tag) for each tag in the tag set, and then assign the tag having the max P(tag/w).\n",
    "\n",
    "We'll store the assigned tags in a list of tuples, similar to the list 'train_tagged_words'. Each tuple will be a (token, assigned_tag). As we progress further in the list, each tag to be assigned will use the tag of the previous token.\n",
    "\n",
    "Note: P(tag|start) = P(tag|'.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95414"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_Vanilla(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5262"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tagged words\n",
    "test_run_base = [tup for sentence in test_set for tup in sentence]\n",
    "test_run_base\n",
    "\n",
    "# list of words\n",
    "test_tagged_words = [tup[0] for sentence in test_set for tup in sentence]\n",
    "len(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "random.seed(100)\n",
    "\n",
    "# choose random 5 sentences\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sentences\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  37.65242886543274\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_Vanilla(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Viterbi Algorithm Accuracy:  90.06211180124224\n"
     ]
    }
   ],
   "source": [
    "# get accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "vanilla_viterbi_accuracy = len(check)*100/len(tagged_seq)\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ', vanilla_viterbi_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to increase the accuracy of out algorithm, we need to find out the words which were tagged incorrectly by vanila viterbi algorithm and then analyze this data to check what all improvements can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('continuingly', '.'), ('continuingly', 'ADV')),\n",
       " (('directed', '.'), ('directed', 'VERB')),\n",
       " (('mining', '.'), ('mining', 'NOUN')),\n",
       " (('hugging', '.'), ('hugging', 'VERB')),\n",
       " (('matters', 'NOUN'), ('matters', 'VERB')),\n",
       " (('*T*-15', '.'), ('*T*-15', 'X')),\n",
       " (('fine', 'NOUN'), ('fine', 'ADV')),\n",
       " (('plaintive', '.'), ('plaintive', 'ADJ')),\n",
       " (('high-minded', '.'), ('high-minded', 'ADJ')),\n",
       " (('assurance', '.'), ('assurance', 'NOUN')),\n",
       " (('reading', 'NOUN'), ('reading', 'VERB')),\n",
       " (('sticky', '.'), ('sticky', 'ADJ')),\n",
       " (('fingers', '.'), ('fingers', 'NOUN')),\n",
       " (('sweaty', '.'), ('sweaty', 'ADJ')),\n",
       " (('Eliminate', '.'), ('Eliminate', 'VERB')),\n",
       " (('more', 'ADV'), ('more', 'ADJ'))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get list of words which were tagged incorrectly by vanila viterbi\n",
    "incorrect_tagged_cases = [j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_tagged_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above set it is clear that all unknown words are tagged with Tag ADJ as this is the first tag in tags list. If an unknown word is countered then this tag is assigned as the emission probability for an unknown word is 0.\n",
    "\n",
    "Let's modify the vanila Viterbi algorithm to tackle this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Modification-Technique I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First solution for unknown words: \n",
    "We can do the assignment based on transition probabilities in case of of unknown words since emission probability for unknown word is zero and vanilla viterbi algorithm is assigning ADJ tag to all unknown words which is resulting in tagging errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_modified(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        \n",
    "        # if probability is zero (unknown word) then use transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            \n",
    "            # getting state for which transition probability is maximum\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "                           \n",
    "        else:\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "        \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "tagged_seq_modified = Viterbi_modified(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9316770186335404"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq_modified, test_run_base) if i == j] \n",
    "modified_viterbi_accuracy = len(check)/len(tagged_seq)\n",
    "modified_viterbi_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Tag occurance probability weights\n",
    "\n",
    "we will apply weights based on the probability of tag occurance to the transition probabilities of tags and then use the resulting probability for predicting unknown words.\n",
    "\n",
    "This scheme will also take into account that some POS tags are more likely to occur as compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 0.11626176452092984),\n",
       " ('PRON', 0.027165824721738948),\n",
       " ('X', 0.06568218500429707),\n",
       " ('NOUN', 0.28661412371350115),\n",
       " ('ADP', 0.09815121470643721),\n",
       " ('VERB', 0.1346552916762739),\n",
       " ('ADJ', 0.06372230490284445),\n",
       " ('ADV', 0.03151529125704823),\n",
       " ('DET', 0.0865386630892741),\n",
       " ('CONJ', 0.022491458276563188),\n",
       " ('PRT', 0.032007881442974825),\n",
       " ('NUM', 0.03519399668811705)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a list containing tuples of POS tags and POS tag occurance probability, based on training data\n",
    "tag_prob = []\n",
    "total_tag = len([tag for word,tag in train_tagged_words])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged_words if tag==t]\n",
    "    tag_prob.append((t,len(each_tag)/total_tag))\n",
    "\n",
    "tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_modified(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "       \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p             \n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use weighted transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                 \n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  36.441455125808716\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_modified(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Accuracy using weighted probability is:  93.16770186335404\n"
     ]
    }
   ],
   "source": [
    "modified_viterbi_accuracy = len(check)*100/len(tagged_seq)\n",
    "print('Modified Accuracy using weighted probability is: ',modified_viterbi_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('continuingly', 'NOUN'), ('continuingly', 'ADV')),\n",
       " (('directed', 'NOUN'), ('directed', 'VERB')),\n",
       " (('matters', 'NOUN'), ('matters', 'VERB')),\n",
       " (('*T*-15', 'NOUN'), ('*T*-15', 'X')),\n",
       " (('fine', 'NOUN'), ('fine', 'ADV')),\n",
       " (('plaintive', 'NOUN'), ('plaintive', 'ADJ')),\n",
       " (('high-minded', 'NOUN'), ('high-minded', 'ADJ')),\n",
       " (('reading', 'NOUN'), ('reading', 'VERB')),\n",
       " (('sticky', 'NOUN'), ('sticky', 'ADJ')),\n",
       " (('sweaty', 'NOUN'), ('sweaty', 'ADJ')),\n",
       " (('more', 'ADV'), ('more', 'ADJ'))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by modified Viterbi as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "- mining: correctly tagged as NOUN\n",
    "- hugging: correctly tagged as VERB\n",
    "- assurance: correctly tagged as NOUN\n",
    "- fingers: correctly tagged as NOUN\n",
    "- Eliminate: correctly tagged as VERB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Modification-Technique II\n",
    "second solution for unknown words:\n",
    "\n",
    "backoff to rule based tagger in case of unknown words.\n",
    "Let's define a rule based tagger as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                   # nouns\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification in Viterbi Algorithm : Backoff to rule based tagger in case unknown word is encountered.\n",
    "def Viterbi_rulebased(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "       \n",
    "        \n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)]                \n",
    "            \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  37.53449773788452\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_rulebased(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified rulebased Viterbi Accuracy:  92.54658385093168\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "rulebased_viterbi_accuracy = len(check)*100/len(tagged_seq)\n",
    "print('Modified rulebased Viterbi Accuracy: ', rulebased_viterbi_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('continuingly', 'NOUN'), ('continuingly', 'ADV')),\n",
       " (('mining', 'VERB'), ('mining', 'NOUN')),\n",
       " (('matters', 'NOUN'), ('matters', 'VERB')),\n",
       " (('fine', 'NOUN'), ('fine', 'ADV')),\n",
       " (('plaintive', 'NOUN'), ('plaintive', 'ADJ')),\n",
       " (('high-minded', 'VERB'), ('high-minded', 'ADJ')),\n",
       " (('note', 'VERB'), ('note', 'NOUN')),\n",
       " (('reading', 'NOUN'), ('reading', 'VERB')),\n",
       " (('sticky', 'NOUN'), ('sticky', 'ADJ')),\n",
       " (('sweaty', 'NOUN'), ('sweaty', 'ADJ')),\n",
       " (('Eliminate', 'NOUN'), ('Eliminate', 'VERB')),\n",
       " (('more', 'ADV'), ('more', 'ADJ'))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further modification in rule based Viterb: We know that the rule based tagger assigns 'NOUN' by default if word does not fall in any rule, to correct this let's assign the tags for any such word based purely on transition probability of tags.\n",
    "\n",
    "So, first we will modify the rule based tagger to output 'NN' instead of 'NOUN' in case word does not satisfy any rules. We also observe that any capitalized word can still be defaulted as 'NOUN' so will add one more rule for that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'^[A-Z][a-z].*', 'NOUN'),       # NOUN\n",
    "    (r'.*', 'NN')                     # default\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified Viterbi\n",
    "def Viterbi_rulebased(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1] \n",
    "        \n",
    "      \n",
    "        # getting state for which probability is maximum\n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "            \n",
    "            # if unknown word does not satisfy any rule, find the tag with maximum transition probability\n",
    "            if state_max == 'NN':\n",
    "                pmax = max(p_transition)\n",
    "                state_max = T[p_transition.index(pmax)]                 \n",
    "                \n",
    "        else:\n",
    "             if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  37.37566018104553\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_rulebased(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi Algorithm Accuracy:  92.54658385093168\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "rulebased_viterbi_accuracy = len(check)*100/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',rulebased_viterbi_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('continuingly', 'NOUN'), ('continuingly', 'ADV')),\n",
       " (('mining', 'VERB'), ('mining', 'NOUN')),\n",
       " (('matters', 'NOUN'), ('matters', 'VERB')),\n",
       " (('fine', 'NOUN'), ('fine', 'ADV')),\n",
       " (('plaintive', 'NOUN'), ('plaintive', 'ADJ')),\n",
       " (('high-minded', 'VERB'), ('high-minded', 'ADJ')),\n",
       " (('note', 'VERB'), ('note', 'NOUN')),\n",
       " (('reading', 'NOUN'), ('reading', 'VERB')),\n",
       " (('sticky', 'NOUN'), ('sticky', 'ADJ')),\n",
       " (('sweaty', 'NOUN'), ('sweaty', 'ADJ')),\n",
       " (('Eliminate', 'NOUN'), ('Eliminate', 'VERB')),\n",
       " (('more', 'ADV'), ('more', 'ADJ'))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by rule based Viterbi as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "- *T*-15: correctly tagged as X\n",
    "- directed: correctly tagged as VERB\n",
    "- hugging: correctly tagged as VERB\n",
    "- assurance: correctly tagged as NOUN\n",
    "- fingers: correctly tagged as NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Sample test sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_sent = text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta',\n",
       " 'I would like to see flights from Denver to Philadelphia.',\n",
       " 'Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.',\n",
       " 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of untagged words\n",
    "sample_test_words = [word for sent in sample_test_sent for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  38.650694847106934\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi_Vanilla(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', '.'),\n",
       " ('Android', '.'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', '.'),\n",
       " ('worldwide', '.'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', '.'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', '.'),\n",
       " ('Google', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', '.'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', '.'),\n",
       " ('that', 'DET'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', '.'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", '.'),\n",
       " ('firehose.', '.'),\n",
       " ('Twitter', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', '.'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', '.'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', '.'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', '.'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', '.'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', '.'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('2018', '.'),\n",
       " ('FIFA', '.'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', '.'),\n",
       " ('FIFA', '.'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', '.'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', '.'),\n",
       " ('contested', '.'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', '.'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', '.'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', '.'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', '.'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', '.'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', '.'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', '.'),\n",
       " ('NASA', '.'),\n",
       " ('invited', '.'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', '.'),\n",
       " ('Satellite.', '.')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that several words have been misclassified by vanilla Viterbi POS tagger, for example:\n",
    "\n",
    "Android as ADJ, \n",
    "Google as ADJ, \n",
    "OS as ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  39.90813326835632\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi_rulebased(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NOUN'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'VERB'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'NOUN'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'NOUN'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NOUN'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NOUN'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'NOUN'),\n",
       " ('NASA', 'NOUN'),\n",
       " ('invited', 'VERB'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'NOUN'),\n",
       " ('Satellite.', 'NOUN')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these cases were correctly POS tagged by Viterbi_2:\n",
    "\n",
    "- Android as NOUN\n",
    "- Google as NOUN\n",
    "- OS as NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vannila Viterbi Accuracy: 90.06211180124224\n",
      "Modified Viterbi Accuracy: 93.16770186335404\n",
      "Rule Based Viterbi Accuracy: 92.54658385093168\n"
     ]
    }
   ],
   "source": [
    "print(\"Vannila Viterbi Accuracy: \"+ str(vanilla_viterbi_accuracy))\n",
    "print(\"Modified Viterbi Accuracy: \"+ str(modified_viterbi_accuracy))\n",
    "print(\"Rule Based Viterbi Accuracy: \"+ str(rulebased_viterbi_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by modified Viterbi as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "- directed: correctly tagged as VERB\n",
    "- hugging: correctly tagged as VERB\n",
    "- *T*-15: correctly tagged as X\n",
    "- fingers: correctly tagged as NOUN\n",
    "- assurance: correctly tagged as NOUN\n",
    "- mining: correctly tagged as NOUN\n",
    "- Eliminate: correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than above list following tags got corrected on sample data:\n",
    "- Words like 'Twitter', 'Android', 'Google' are properly tagged with 'NOUN' in modified Viterbi Algorithm\n",
    "- Words like 'NASA', 'FIFA' are correctly tagged as 'NOUN' (All Caps of a word generally will be an abbrevation and it is a noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
